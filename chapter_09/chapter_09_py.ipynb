{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c33f29c-46e0-4328-beda-8f758684b57d",
   "metadata": {},
   "source": [
    "# [The StatQuest Illustrated Guide to Statistics](https://www.amazon.com/dp/B0GMP7Z9ZL)\n",
    "## Chapter 09 - Determining How Much Data to Collect with Power Analyses!!!\n",
    "\n",
    "Copyright 2026, Joshua Starmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356cead-21bc-4a79-bfcc-972787453cab",
   "metadata": {},
   "source": [
    "In this notebook we'll learn...\n",
    "\n",
    "- How sample sizes influences our confidence in the accuracy of an Estimated Mean.\n",
    "- How to do a Power Analysis for *t*-test.\n",
    "\n",
    "**NOTE:**\n",
    "This tutorial assumes that you have installed **[Python](https://www.python.org/)** and read Chapter 9 in **[The StatQuest Illustrated Guide to Statistics](https://www.amazon.com/dp/B0GMP7Z9ZL)**.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40e593-e003-4a44-99b2-20e4c4cb7c13",
   "metadata": {},
   "source": [
    "Since we're using Python, the first thing we do is load in some modules that will help us do math and plot graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b3362-46fc-49da-94cc-6e4165b887d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # to generate random numbers\n",
    "from scipy.stats import norm, expon # to generate normal and exponential curves\n",
    "import seaborn as sns # to draw a graphs and have them look somewhat nice\n",
    "from statsmodels.stats.power import TTestIndPower ## to do a power analysis for a t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e980620-d170-42b2-88a3-6b6339a820b6",
   "metadata": {},
   "source": [
    "# The effects of sample size on our confidence in the accuracy of an Estimated Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8e1f39-85a8-4df0-aae4-c6fd99f186be",
   "metadata": {},
   "source": [
    "Here we will take samples from two distributions, the normal distribution and the exponential distribution, and show how the estimated means calculated from those samples tend to get better when the sample size is larger. In other words, our confidence in the accuracy of an estimated mean improves with larger sample size.\n",
    "\n",
    "We'll start with showing how this works with the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c67c97-ccb4-49a3-b454-ed7bf57d95e2",
   "metadata": {},
   "source": [
    "# Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f8e86-13c9-41c5-974c-c234427f01c6",
   "metadata": {},
   "source": [
    "First, let's just draw a normal distribution with mean = 0 and standard deviation = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e3ba1-65fc-4e61-a010-d7604a282475",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create an array of x-axis coordinates\n",
    "x_axis = np.arange(start=-5, \n",
    "                   stop=5.1, \n",
    "                   step=0.1)\n",
    "\n",
    "## print out the first 10 values\n",
    "x_axis[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee9572e-8450-40b7-96d7-661dac7fd895",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create an array of y-axis coordinates that correspond to each value in x_axis\n",
    "## NOTE: 'loc' = location = the mean. This is because the mean is also called\n",
    "##       a \"location parameter\" since the mean determines the location of the\n",
    "##       center, or highest point, of the distribution.\n",
    "\n",
    "##       'scale' = standard deviation. This is because the standard deviation is\n",
    "##       also called a \"scale parameter\". This is because the standard deviation\n",
    "##       scales the height of the distribution. The larger the standard deviation\n",
    "##       the smaller the height.\n",
    "y_axis = norm.pdf(x=x_axis, \n",
    "                  loc=0, \n",
    "                  scale=1)\n",
    "\n",
    "## print out the first 10 values\n",
    "y_axis[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6f0d5-74c9-4dfb-8b43-124ea0d86a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=x_axis, y=y_axis,\n",
    "            color='lightgrey',\n",
    "            linewidth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a2294-fa80-4abf-a6e1-003d3ecfb388",
   "metadata": {},
   "source": [
    "Now let's add the estimated means, calculated with different sample sizes, to the graph. We'll start with *n*=1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc29196-aab5-4e19-9b66-65cb35c498d2",
   "metadata": {},
   "source": [
    "## *n* = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd669c-88e0-4a28-b2a1-21efcba765eb",
   "metadata": {},
   "source": [
    "First, calculate the means..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1e8ef-1fdd-4d88-9312-0c73658a457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, make sure our results are reproducable\n",
    "np.random.seed(5)\n",
    "\n",
    "num_rand_datasets = 20 # Number of datasets to collect\n",
    "num_datapoints = 1 # Number of points in each dataset\n",
    "\n",
    "## means is an array of estimated mean values calculated\n",
    "## from each dataset.\n",
    "means = np.empty(num_rand_datasets)\n",
    "\n",
    "## y_axis is just a bunch of 0s, one per estimated mean\n",
    "## that we calculate. This is just to put the estimated\n",
    "## means at the bottom of the graph.\n",
    "y_axis_means = [0] * num_rand_datasets\n",
    "\n",
    "## Now create num_rand_datasets datasets\n",
    "## and calculate an estimated mean with each one\n",
    "for i in range(num_rand_datasets):\n",
    "    \n",
    "    sample = np.random.normal(loc=0, scale=1, size=num_datapoints)\n",
    "    means[i] = np.mean(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0411ee93-caeb-4c7f-8e1d-b66dcd07d8d9",
   "metadata": {},
   "source": [
    "...now add them to our graph of the normal curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ffab1-ce5f-4394-9aa7-1a32b43c054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now plot the normal distribution that the datasets\n",
    "## were sampled from...\n",
    "my_curve = sns.lineplot(x=x_axis, y=y_axis,\n",
    "                        color='lightgrey',\n",
    "                        linewidth=5)\n",
    "\n",
    "## ...and the estimated means.\n",
    "my_curve.scatter(means, y_axis_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae0fd3b-ba28-4d47-87a9-783cef6125eb",
   "metadata": {},
   "source": [
    "Bam! Here we see that when *n*=1, the estimated means are spread out between **-2** and **2.5**. Now let's see what happens when we increase the sample size to *n*=2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ea2d5-9cf6-4cdb-af31-e87283d4d29a",
   "metadata": {},
   "source": [
    "# *n* = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293dadfa-62ca-4aef-a1ce-8452862bd5ce",
   "metadata": {},
   "source": [
    "**NOTE:** Increasing the sample size to **2** means setting `num.datapoints` to **2**. Everything else is the same as for *n*=1. First, we calculate the means..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f2c3f-9c3f-4118-b99c-732527fbccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "num_rand_datasets = 20\n",
    "num_datapoints = 2\n",
    "\n",
    "means = np.empty(num_rand_datasets)\n",
    "y_axis_means = [0] * num_rand_datasets\n",
    "\n",
    "for i in range(num_rand_datasets):\n",
    "    \n",
    "    sample = np.random.normal(loc=0, scale=1, size=num_datapoints)\n",
    "    means[i] = np.mean(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c09cd9-5f06-43e1-b70d-a14daeb42415",
   "metadata": {},
   "source": [
    "...then we add them to the a graph of the normal curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d95753-ad61-4297-a68b-faf592894f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_curve = sns.lineplot(x=x_axis, y=y_axis,\n",
    "                        color='lightgrey',\n",
    "                        linewidth=5)\n",
    "\n",
    "my_curve.scatter(means, y_axis_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2686e8-0544-4030-b3c0-42edff93cabe",
   "metadata": {},
   "source": [
    "Bam! Now, when *n*=2, the estimated means span a range of values from about -1,75 to about 1.75. This is a narrower range of values than before. As a result, we should have more confidence in the accuracy of estimated means when *n*=2 compared to when *n*=1.\n",
    "\n",
    "Now let's increase the sample size to *n*=5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e3a46d-f6e0-49be-8dc3-5aec90c7c3c3",
   "metadata": {},
   "source": [
    "## *n* = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f3da2-4e74-4ae7-9dd0-14a0fb4b2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "num_rand_datasets = 20\n",
    "num_datapoints = 5\n",
    "\n",
    "means = np.empty(num_rand_datasets)\n",
    "y_axis_means = [0] * num_rand_datasets\n",
    "\n",
    "for i in range(num_rand_datasets):\n",
    "    \n",
    "    sample = np.random.normal(loc=0, scale=1, size=num_datapoints)\n",
    "    means[i] = np.mean(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade70e87-a558-4205-ab86-9eb00e3565ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_curve = sns.lineplot(x=x_axis, y=y_axis,\n",
    "                        color='lightgrey',\n",
    "                        linewidth=5)\n",
    "\n",
    "my_curve.scatter(means, y_axis_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74afa06-00f1-4163-8c0a-16de990dee24",
   "metadata": {},
   "source": [
    "Bam! Setting the sample size to *n*=5 resulted in the estimated means forming a tighter cluster around the population mean, 0. Now let's see what happens when we increase the sample size one last time to *n*=10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3bb06c-982b-4e96-a3dd-bea67cb469f5",
   "metadata": {},
   "source": [
    "## *n* = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c8f19-3e61-4471-bb5e-300202b4b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "num_rand_datasets = 20\n",
    "num_datapoints = 10\n",
    "\n",
    "means = np.empty(num_rand_datasets)\n",
    "y_axis_means = [0] * num_rand_datasets\n",
    "\n",
    "for i in range(num_rand_datasets):\n",
    "    \n",
    "    sample = np.random.normal(loc=0, scale=1, size=num_datapoints)\n",
    "    means[i] = np.mean(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7dda4b-d0c5-41b1-94b7-5be5f23a7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_curve = sns.lineplot(x=x_axis, y=y_axis,\n",
    "                        color='lightgrey',\n",
    "                        linewidth=5)\n",
    "\n",
    "my_curve.scatter(means, y_axis_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140fd1b-0803-41bc-96a3-899d81b2e229",
   "metadata": {},
   "source": [
    "Bam! Now we see that each time we increase the sample size, the estimated means cluser closer and closer to the true, population mean. Thus, the larger the sample size, the more confidence we can have that an particular estimated mean is close to the population mean.\n",
    "\n",
    "Now that we've seen how increasing the sample size results in the estimated mean being closer to the population mean for the **Normal Distribution**, let's see what happens when we use an **Exponential Distribution**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a864b-f0a0-424a-a79b-ae5cded2047f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646ee0bd-4637-43bf-aa20-568b637f1e5e",
   "metadata": {},
   "source": [
    "# Exponential Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a9b399-bfee-4fb6-afeb-df550664a3be",
   "metadata": {},
   "source": [
    "First, let's just draw an exponential distribution with mean = 2.\n",
    "\n",
    "**NOTE:** The expoenential distribution function, `expon.pdf()` that comes with `scipy.stats` has one parameter that we need to set called the **mean**. In these examples, we'll set the mean to 2.\n",
    "\n",
    "**ALSO NOTE:** Since the expoential distribution is not symmetrical, we'll draw a vertical line at the mean value so it is easy to identify. We can do this with the `axvline()` function, which specifically draws vertical lines. To draw a vertical line, you only need to specify the x-axis location for `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e0ab1-3a09-4635-915d-e4a9d2a9b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the x and y-axis coordinates for an\n",
    "## exponential distribution with mean = 2.\n",
    "exp_mean = 2\n",
    "\n",
    "x_axis = np.arange(start=0, \n",
    "                   stop=10, \n",
    "                   step=0.1)\n",
    "\n",
    "y_axis = expon.pdf(x_axis, scale=exp_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a048ee-3a20-421f-ab1e-bec2f5f76b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now draw the curve and a vertical line at the mean\n",
    "my_curve = sns.lineplot(x=x_axis, y=y_axis,\n",
    "                        color='lightgrey',\n",
    "                        linewidth=5)\n",
    "\n",
    "## NOTE: Since the expoential distribution is not symmetrical,\n",
    "## we'll draw a vertical line at the mean value so it is easy\n",
    "## to identify.\n",
    "my_curve.axvline(x=exp_mean, \n",
    "                 color=\"lightgrey\",\n",
    "                 linewidth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3272cb4b-e843-4dae-91cd-a439b74bcbd6",
   "metadata": {},
   "source": [
    "Bam! Now we know how to draw an exponential distribution and a vertical line at mean value. Now let's see how the estimated means are distributed when the sample size = **1**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f898c689-2bbe-41ed-bcbd-179504fc02dd",
   "metadata": {},
   "source": [
    "## *n*=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd9bb2b-d1c2-472b-919a-0043eceb13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "num_rand_datasets = 20\n",
    "num_datapoints = 1\n",
    "\n",
    "means = np.empty(num_rand_datasets)\n",
    "y_axis_means = [0] * num_rand_datasets\n",
    "\n",
    "for i in range(num_rand_datasets):\n",
    "    \n",
    "    sample = np.random.exponential(scale=exp_mean, size=num_datapoints)\n",
    "    means[i] = np.mean(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66107f93-cffb-4cf3-8d1d-1d2b6003304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_curve = sns.lineplot(x=x_axis, y=y_axis,\n",
    "                        color='lightgrey',\n",
    "                        linewidth=5)\n",
    "\n",
    "my_curve.axvline(x=exp_mean, \n",
    "                 color=\"lightgrey\",\n",
    "                 linewidth=5,\n",
    "                 zorder=0) ## We add \"zorder=0\" to force python to draw\n",
    "                           ## the vertical line under everything else\n",
    "\n",
    "my_curve.scatter(means, \n",
    "                 y_axis_means, \n",
    "                 zorder=10) ## We add \"zorder=10\" to force python to draw\n",
    "                            ## the means on top of everything else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a75f1b3-6a14-4565-8cf3-1e39c75eb910",
   "metadata": {},
   "source": [
    "Now that we can see the range of values estiamted means calculated with *n* = 1 measurements have, let's compare them to estimated means calculated with *n* = 2 measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcdb9b7-68b0-4cb8-898e-71488132de8e",
   "metadata": {},
   "source": [
    "## *n* = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeff70f-b1b4-40e0-88d9-fb0ad69a7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "num_rand_datasets = 20\n",
    "num_datapoints = 2\n",
    "\n",
    "means = np.empty(num_rand_datasets)\n",
    "y_axis_means = [0] * num_rand_datasets\n",
    "\n",
    "for i in range(num_rand_datasets):\n",
    "    \n",
    "    sample = np.random.exponential(scale=exp_mean, size=num_datapoints)\n",
    "    means[i] = np.mean(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b40d1b-e101-4bd4-a010-1dd91573191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_curve = sns.lineplot(x=x_axis, y=y_axis,\n",
    "                        color='lightgrey',\n",
    "                        linewidth=5)\n",
    "\n",
    "my_curve.axvline(x=exp_mean, \n",
    "                 color=\"lightgrey\",\n",
    "                 linewidth=5,\n",
    "                 zorder=0)\n",
    "\n",
    "my_curve.scatter(means, \n",
    "                 y_axis_means, \n",
    "                 zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f12ad-923d-4683-bd52-79f54396887f",
   "metadata": {},
   "source": [
    "...and the results are not exaclty what we were hoping for. When *n* = 2 we see a wider range of values for the esimtated means. However, keep in mind that we're only looking at **20** different estimated means in each case, and it could be (and, in theory, will be) different if we looked at way more estimated means.\n",
    "\n",
    "We could test that theory by increasing the value for `num.rand.datasets`, but I'll leave that as an exercise for the reader. For now, let's see what happens when we increase the sample size to *n* = 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b9bb0-391c-4931-bae7-6dbc6362d20e",
   "metadata": {},
   "source": [
    "## *n* = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d80817-94bc-431c-b3d8-96270b278bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "num_rand_datasets = 20\n",
    "num_datapoints = 5\n",
    "\n",
    "means = np.empty(num_rand_datasets)\n",
    "y_axis_means = [0] * num_rand_datasets\n",
    "\n",
    "for i in range(num_rand_datasets):\n",
    "    \n",
    "    sample = np.random.exponential(scale=exp_mean, size=num_datapoints)\n",
    "    means[i] = np.mean(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8810f-a521-48aa-9b09-5ff42b8a0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_curve = sns.lineplot(x=x_axis, y=y_axis,\n",
    "                        color='lightgrey',\n",
    "                        linewidth=5)\n",
    "\n",
    "my_curve.axvline(x=exp_mean, \n",
    "                 color=\"lightgrey\",\n",
    "                 linewidth=5,\n",
    "                 zorder=0)\n",
    "\n",
    "my_curve.scatter(means, \n",
    "                 y_axis_means, \n",
    "                 zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50cc418-a836-4090-a973-12fe4031ace8",
   "metadata": {},
   "source": [
    "Now, with the sampel size set to *n* = 5, we start to see that the means have a slightly smaller range of values compared to when *n* = 1 and when *n* = 2. Now let's increase the sample size to *n* = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4427d-70f9-455b-bb95-61e47b17a6d5",
   "metadata": {},
   "source": [
    "## *n* = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e075d5-21b8-492f-ad17-1ae528f88bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "num_rand_datasets = 20\n",
    "num_datapoints = 10\n",
    "\n",
    "means = np.empty(num_rand_datasets)\n",
    "y_axis_means = [0] * num_rand_datasets\n",
    "\n",
    "for i in range(num_rand_datasets):\n",
    "    \n",
    "    sample = np.random.exponential(scale=exp_mean, size=num_datapoints)\n",
    "    means[i] = np.mean(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f2c2f-cacd-4863-a88a-c07a1b444660",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_curve = sns.lineplot(x=x_axis, y=y_axis,\n",
    "                        color='lightgrey',\n",
    "                        linewidth=5)\n",
    "\n",
    "my_curve.axvline(x=exp_mean, \n",
    "                 color=\"lightgrey\",\n",
    "                 linewidth=5,\n",
    "                 zorder=0)\n",
    "\n",
    "my_curve.scatter(means, \n",
    "                 y_axis_means, \n",
    "                 zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc61da21-c8ea-4ac8-bfb8-d15fbded76ee",
   "metadata": {},
   "source": [
    "And here is where we really see the estimated means cluster more tightly around the population mean, **2**. As a result, when *n*=10, we can have more confidence that any individual estimated mean will be closer to the population mean.\n",
    "\n",
    "# BAM!\n",
    "\n",
    "Now let's learn how to do a Power Analysis for a t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ec318-c673-4428-ac31-3d29818c022f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82cc56d-df35-4f82-bdae-b42775268d03",
   "metadata": {},
   "source": [
    "# How to do a Power Analysis for *t*-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e054c4bb-34c6-47a0-8e78-e778d5217ba3",
   "metadata": {},
   "source": [
    "For pretty much every experiment, it's a good idea to determine if the sample size will be large enough to reject the null hypothesis if the null hypothesis is, indeed, false. In other words, you should always do a **Power Analysis**.\n",
    "\n",
    "To do a **Power Analysis** for a *t*-test in **Python**, we can use the `TTestIndPower()` and its `solve_power` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f37ef-4b96-4708-ac88-9d7d48f1afe5",
   "metadata": {},
   "source": [
    "We'll start using relatively standard parameters values. We'll set probability that we will correctly reject the null hypothesis, if it is indeed false, to 0.8 with `power=0.8`, the threshold for significance to 0.05 with `sig.level=0.05`.\n",
    "\n",
    "Now, the last two things we need to specify are our estimates of the difference the population means and the standard deviation, using the same value for both populations. For this example, let's assume the difference in the populations means is 1, and we'll assume the standard deviation is also 1. So the effect size is 1/1, and we'll use that to set `effect_size=1/1`.\n",
    "\n",
    "So, with all those parameters set, we have the following command that we can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4591057-5d8e-4992-a0ff-7e691944d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a t-test power analysis object\n",
    "analysis = TTestIndPower()\n",
    "\n",
    "## do a power anlysis\n",
    "analysis.solve_power(effect_size=1/1, power=0.80, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6acd961-1736-4c4e-a5b4-f7991f832dc5",
   "metadata": {},
   "source": [
    "The output, `16.714722572276173` tells us that we need, exactly **16.71477** obesrvations in each group. Why the this value isn't rounded to the nearest integer is a complete mystery to me. I'm not sure how it would be remotely possible to gather **16.714722572276173** measurements. But, whatever, no one asked me.\n",
    "\n",
    "Anyway, now let's compare that value to what we get when our estimate of the standard deviation is smaller, **0.5**. This means we'll set `effectsize=1/0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4943adc-875b-4cef-bbd0-f9e80d09deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## do a power anlysis\n",
    "analysis.solve_power(effect_size=1/0.5, power=0.80, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd618a2-fd0f-48f8-8aec-99ee19cb240f",
   "metadata": {},
   "source": [
    "So, when the estimated standard deviation is halfed, the number of measurements requires to get the power we want (80% probability that we will correctly reject the null hypothesis if it is false) drops by over two thirds. Instead of gathering **17** measurements per group, now we just need **5**.\n",
    "\n",
    "# Double BAM!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfbbaa5-1333-411f-9df7-c7923762c2a1",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
