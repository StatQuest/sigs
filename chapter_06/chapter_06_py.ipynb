{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c33f29c-46e0-4328-beda-8f758684b57d",
   "metadata": {},
   "source": [
    "# [The StatQuest Illustrated Guide to Statistics](https://www.amazon.com/dp/B0GMP7Z9ZL)\n",
    "## Chapter 06 - Making Decisions and Predictions with Linear Regression!!!\n",
    "\n",
    "Copyright 2026, Joshua Starmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356cead-21bc-4a79-bfcc-972787453cab",
   "metadata": {},
   "source": [
    "In this notebook we'll learn how to...\n",
    "\n",
    "- Fit a line to data with the `ols()` function.\n",
    "- Calculate the Sum of the Squared Residuals and $R^2$.\n",
    "- Generating a Linear Regression Summary with `results.summary()`.\n",
    "- Calculate a *p*-value for the $R^2$ using the null hypothesis to build a histogram.\n",
    "- Calculate an *F*-value and corresponding *p*-value using the Sum of the Squared Residuals.\n",
    "\n",
    "**NOTE:**\n",
    "This tutorial assumes that you have installed **[Python](https://www.python.org/)** and read Chapter 6 in **[The StatQuest Illustrated Guide to Statistics](https://www.amazon.com/dp/B0GMP7Z9ZL)**.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8dea4-330c-4956-82c0-407a1e961c75",
   "metadata": {},
   "source": [
    "Since we're using Python, the first thing we do is load in some modules that will help us do math and plot graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5096da-e0ce-4159-8273-d3772ee3b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # to generate random numbers\n",
    "import pandas as pd # to use DataFrames\n",
    "import seaborn as sns # to draw a graphs and have them look somewhat nice\n",
    "import matplotlib.pyplot as plt # give us easy control of the range of values for\n",
    "                                # the x and y axes.\n",
    "import statsmodels.formula.api as smf ## to do linear regression with ols()..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3bb06c-982b-4e96-a3dd-bea67cb469f5",
   "metadata": {},
   "source": [
    "# Fitting a line to data with the `ols()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8c8301-69b3-4bad-adff-e9085e74d424",
   "metadata": {},
   "source": [
    "If we're going to fit a line to some data, then the first thing we need is some data. In this example, we'll use the dataset illustrated in Chapter 6, which has the number of stores in one column and the revenue in another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c99451-2846-480c-88cd-cd110cdc41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's put the data into a DataFrame\n",
    "num_stores = [2, 12, 15]\n",
    "revenue = [3, 12.5, 7]\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'num_stores': num_stores,\n",
    "    'revenue': revenue\n",
    "})\n",
    "\n",
    "# print out the DataFrame\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfca141-d2af-44d1-92ca-cf44bc9430d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plot= sns.scatterplot(x='num_stores', \n",
    "                y='revenue', \n",
    "                data=data,\n",
    "                s=300, # scale the size of the points\n",
    "                color='salmon')  # set the color\n",
    "plt.xlim(0, 16)\n",
    "plt.ylim(0, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda5d12-c683-4f22-87b7-a82aaef4c6fc",
   "metadata": {},
   "source": [
    "Now that we've plotted our raw data, let's add a linear regression line to it. This requires two steps. First, we determine the slope and y-axis intercept for the linear regression line and second, we use tthe slope and y-axis intercept to draw a line on the graph.\n",
    "\n",
    "We'll start by determining the slope and y-axis intercept.\n",
    "\n",
    "**NOTE:** In Python there are a ton of ways to do linear regression to determine the slope and y-axis intercept. One very popular method is with the `LinearRegression()` function that is part of the `scikit-learn` package. However, in these tutorials, we will not use `LinearRegression()` function or many other popular plotting functions, like `regplot()`, because because they don't return basic statistics like $R^2$ and it's *p*-value. In other words, the `LinearRegression()` method is really only intended for people less interested in basic statistics and `regplot()` is only useful for people less interested in the y-axis intercept and the slope that the regression calculates.\n",
    "\n",
    "Thus, in order to determine the slope and y-axis intercept, we'll use the `ols()` function that comes with the `statsmodels.formula.api` package, where **ols** stands for **Ordingary Least Squares**, which is the method we used to optimize parameters in the book. Anyway, the `old()` function will return an object that we can then use the fit a linear regression model to our data and then print out the results.\n",
    "\n",
    "The `ols()` function can seem a little strange in that the first thing we pass it is called a **formula**. A **formula** has the form...\n",
    "\n",
    "**Thing we want to predict ~ Variables we use to make predictions**\n",
    "\n",
    "...where the **Thing we want to predict** is on the left side of a **~** character, and the **Wariables we want to use to make prediction** are on the right side. In this example, that means we will use `revenue ~ num_stores` as the formula, because we want to use `num_stores` to predict `revenue`.\n",
    "\n",
    "Anyway, when using the `ols()` function, the other important thing to do is pass in the data, which we do with `data=data`, since all of our data is stored in a data.frame called `data`.\n",
    "\n",
    "**NOTE:** One bonus we get for using `ols()` from `statsmodels.formula.api` is that the formula that we use in Python is the same as the formula that we would use if we were doing this in `R`. In other words, by using the formula notation, we can, in theory, go back and forth between these two programming languages using the same notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc624798-7985-4635-9056-4cf801378c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, create the model object...\n",
    "model = smf.ols(\"revenue ~ num_stores\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2839da4d-b5e4-4e6a-9ca0-3db1d0cdea18",
   "metadata": {},
   "source": [
    "Now that we've created an ordinary least squares model called `model`, we can fit it to our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf1ab3-a4b9-408b-a4b9-95a46b0ec5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now fit the model to the data (optimize the 2 parameters,\n",
    "## the y-axis intercept and the slope)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9846b6b-2aac-4cf4-812d-b341ad33d3ef",
   "metadata": {},
   "source": [
    "...and then print out the values for the y-axis intercept and the slope with `results.params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc31b0f-7279-4a40-9b2f-c92293ed8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc7370-5375-4d86-afc4-9b1a0b43fec9",
   "metadata": {},
   "source": [
    "**NOTE:** We can also print out the individual parameters by using their names..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22233bf9-adaa-456e-a76f-4dceeed93901",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params.Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d7c5c-48e0-479e-abcb-512484484d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params.num_stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73707c85-1cce-4bd8-b9b3-e9d4b58bbea6",
   "metadata": {},
   "source": [
    "Now, if we want to add the linear regression line to our graph of the data, we can do that with the `abline()` function. `abline()` makes this super easy by having an argument, `reg` that we can pass `lr.line` to and it will take care of all the details associated with drawing the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb64b4d-f7b6-4d88-880c-1cc31e110a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, draw the data...\n",
    "my_plot= sns.scatterplot(x='num_stores', \n",
    "                y='revenue', \n",
    "                data=data,\n",
    "                s=300, # scale the size of the points\n",
    "                color='salmon')  # set the color\n",
    "\n",
    "plt.xlim(0, 16)\n",
    "plt.ylim(0, 16)\n",
    "\n",
    "## ...now add the regression line.\n",
    "my_plot.axline(xy1=(0, results.params.Intercept),\n",
    "               slope=results.params.num_stores, \n",
    "               color='deepskyblue', \n",
    "               linestyle='-',\n",
    "               linewidth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894056db-3f5b-4a9b-b449-16ca2ff26fad",
   "metadata": {},
   "source": [
    "# BAM!\n",
    "\n",
    "Now that we have a graph of our data and it's corresponding linear regression line, let's learn how interpret the statistics associated with the linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4f6a0-8c97-4777-bce6-34da77c350f2",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad8b45e-4c4c-491b-9af7-5d959e1d26ae",
   "metadata": {},
   "source": [
    "# Generating a Linear Regression Summary with `summary()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd33bc-34b5-4e14-b4d9-06a13fefe629",
   "metadata": {},
   "source": [
    "Earlier, when we printed the ouput from `ols()` that we saved in `results`, we specifically printed out the y-axis intercept and the slope. However, `results` contains a lot more data that we can access by using its `summary()` method.\n",
    "\n",
    "**NOTE:** This will print out a lot of stuff, some of which we talk about in the book, some of which we don't. We'll focus on the stuff in the book, which, in my opinion, is the important stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0cc1a3-e091-4b35-af58-ef9ef5d7a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now print out the associated statsitics.\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b9daa-7a52-4307-92d0-95768e5346af",
   "metadata": {},
   "source": [
    "As we can see, the output from `summary()` is pretty extensive. However, right now we just want to know the $R^2$ value and it's associated *p*-value. We can find the value for $R^2$ in the upper right hand corner where it says `R-squared` and see that it is 0.449. The corresponding *p*-value is a few rows down where it says `Prob (F-statistic)`, which refers to how the *p*-value is traditionally calculated, and is 0.533.\n",
    "\n",
    "Using the standard threshold for staistical significance, 0.05, we would fail to reject the Null Hypothesis that there is no relationshiop between the number of stores a company has and its revenue. That's a little bit of a bummer, but, it could be that there is a relationship, but that we just don't have enough data to be confident in saying so.\n",
    "\n",
    "Anyway, `summary()` returns a lot of stuff, and it's not always super easy to find what we need, however, the good news is that we can access individual values, like the $R^2$ value or the *p*-value, directly.\n",
    "\n",
    "For example, to access the $R^2$ value directly, we would use the following command..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac7644-8373-4125-bd6d-fa801ddf83a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aaccbe-58b2-4ba6-ae4b-528e490296ca",
   "metadata": {},
   "source": [
    "Likewise, we can access parameter values (the y-axis intercept and the slope), which are also called coefficients, with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb53593-9bb8-4252-8fc9-8d0c5fa521c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## summary() returns 3 tables\n",
    "summary_stuff = results.summary()\n",
    "## print out the second one, it has \n",
    "## everything related to the coefficients\n",
    "summary_stuff.tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8785e-0d7d-4fa9-a42e-60626ea9c7c2",
   "metadata": {},
   "source": [
    "As we can see, when print out the coefficients, we get all kinds of information in addtion to the values for the y-axis intercept and the slope, which are in the first column labeled **coef**. The next two columns, **std err** and **t**, are not super interesting right now, but the second to the last column **P(>|t|)** is. What this tells us that is the *p*-value for each parameter testing the Null Hypothesis that the parameter value is actually 0.\n",
    "\n",
    "For example, for the estimated y-axis intercept that we calculated from the data is, 2.9622, however, the *p*-value that tests the hypothesis that it actually is equal to 0 is 0.699. This tells us that even though our estimate for the y-axis intercept is non-zero, we can't be confident that it really is.\n",
    "\n",
    "**NOTE:** Although the `summary()` function always returns the *p*-value for the y-axis intercept, it's not used that often. Generally speaking, we don't really care what the y-axis intecept is. What is interesting, however, is the slope and it's *p*-value, because this tells us if we are confident (or not) about a relationship between the two variables we measured. In this case, that would tell us if there is a relationship between Number of Stores and Revenue.\n",
    "\n",
    "So, in this example, when we look at the *p*-value for **num_stores**, the variable that contains the number of stores, we get 0.533, and this tells us that we fail to reject the Null Hypothesis that the slope is 0. In other words, we fail to reject the hypothesis that just using the mean value for Revenue (which is what we would use if the slope was 0), is significantly worse than using our linear regression line.\n",
    "\n",
    "If we want to access the just the *p*-value for **num_stores** directly (and exclude the *p*-value for the y-axis intercept), we have two options: 1) We can use the name of the variable like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d0e34-b041-463b-803c-46dd9b8ea94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pvalues.num_stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13e59e-32f5-4899-b530-8f4ea03c944d",
   "metadata": {},
   "source": [
    "...or, 2) we can use `iloc[1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec1b1b5-35ad-4162-a901-6a17b9e4efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pvalues.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b0f3e0-fbc2-488b-9b41-3af5a078710c",
   "metadata": {},
   "source": [
    "Anyway, now that we know how to do a linear regresion with `lm()` and access and interpret the most important results, let's try to calculate some of these values by hand. We'll start by calculating $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5c952-f887-4010-9ebf-867e7cd47b0f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589b1033-1439-4ec6-8724-4843f756c356",
   "metadata": {},
   "source": [
    "# Calculating the Sum of the Squared Residuals (SSRs) and $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9845d5c-902d-4460-9a7c-7d288c063c26",
   "metadata": {},
   "source": [
    "Even though the `lm()` function calculated $R^2$, it's also helpful to know how to calculate it both by hand. So, let's start with the equation for $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a249c5e3-dded-4d1e-bdb0-6c3d2653c37a",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 24px;\">\n",
    "$R^2 = \\frac{\\textrm{SSR(mean)} - \\textrm{SSR(fit)}}{\\textrm{SSR(mean)}}$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d1e6f-44d1-4014-905c-8a278398aad4",
   "metadata": {},
   "source": [
    "Where SSR(mean) is the Sum of the Squared Residuals around the mean y-axis value, which, in this example, is Revenue, and SSR(fit) is the sum of the squared residuals around the fitted line. We'll start by calculating SSR(mean) and, more specifically, by calculating the mean value for Revenue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643a154-27c7-4845-9473-126f80985f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate mean revenue\n",
    "mean_revenue = np.mean(data['revenue'])\n",
    "\n",
    "## print out the mean revenue\n",
    "mean_revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991ef5b-120a-4c2e-8f63-466cd058998d",
   "metadata": {},
   "source": [
    "Now that we have the mean value for Revenue, we can calculate the Residuals around the mean by subtracting the mean from each Revenue value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3977f24-4de0-49dd-8b60-f8a6be342f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals from mean\n",
    "mean_residuals = data['revenue'] - mean_revenue\n",
    "\n",
    "## print out the residuals\n",
    "mean_residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a6b0c-b9af-4ac9-87b5-20e64b6829e0",
   "metadata": {},
   "source": [
    "Now let's square each Residual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf94b05-22dc-4447-9713-b618538a1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Square the residuals\n",
    "mean_residuals_squared = mean_residuals ** 2\n",
    "\n",
    "## print out the squared residuals\n",
    "mean_residuals_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5bfcdc-b275-4575-a317-e4e0f2090c12",
   "metadata": {},
   "source": [
    "Now we just need to add up the squared residuals. We'll do this by passing `mean_residuals_squared` to the `np.sum()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3beaea-683b-4221-826d-fe41a8cada1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add up the squared residuals\n",
    "ssr_mean = np.sum(mean_residuals_squared)\n",
    "\n",
    "## Print out the SSR(mean)\n",
    "print(ssr_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d14ab-a257-4eb4-9034-2fc3328a60ba",
   "metadata": {},
   "source": [
    "Bam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e56ecda-7712-4271-a7ce-4e6cbed5d30a",
   "metadata": {},
   "source": [
    "Now let's calculate SSR(fit). **NOTE:** We can extract the residuals directly from `results` or we can calculate them by hand. Here, we'll show you how to do it both ways.\n",
    "\n",
    "We'll start by seeing the resduals stored in `results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878ab69-db05-4fbb-a66f-1a043bae9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf5b7e8-d896-4c15-a5fd-550b29788eb9",
   "metadata": {},
   "source": [
    "Now let's calculate the residuals by hand and compare our results.\n",
    "\n",
    "To calculate the residuals by hand, we'll need the x-axis intercept and the slope of the linear regression line. However, we learned how to access those when we first drew the regression line on our graph. So, that's no problem.\n",
    "\n",
    "Next, given the y-axis intercept and the slope, we can predict the revenue for each company in our dataset by multipling the number of stores in `data.num_stores` by the slope and then adding the y-axis intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1b69c-e6f5-432c-992f-5ee56d2564ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_predictions = results.params.Intercept + (results.params.num_stores * data.num_stores)\n",
    "\n",
    "## print out the predicted values\n",
    "fit_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7291bc1-9c1f-4564-b532-0ab93fdac475",
   "metadata": {},
   "source": [
    "Next, we calculate the residuals by subtracting the predicted values from the observed Revenue values in `data.revenue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468941a-e276-40a0-8376-492467b21ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_residuals = data.revenue - fit_predictions\n",
    "\n",
    "## print out the residuals\n",
    "fit_residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20face64-8a80-42b2-9006-8e1066007a98",
   "metadata": {},
   "source": [
    "Bam! We just calculated the residuals around the fitted line by hand. Now let's compare those to residuals stores in `results.resid`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f7c923-09d8-46ca-8959-de0d6f1b5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2819a95f-1086-4f05-acaa-ff61d90440e2",
   "metadata": {},
   "source": [
    "...and we see that, either way we get the residuals, we get the same thing. In other words, when we calculated the residuals by hand, we didn't make a mistake.\n",
    "\n",
    "Now let's finish calculating the SSR(fit) by squaring the residuals..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a13ffa-c2ab-4f93-81ed-f68e40d8bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Square the residuals\n",
    "fit_residuals_squared = fit_residuals ** 2\n",
    "\n",
    "## print out the squared residuals\n",
    "fit_residuals_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ef0a9-9970-489a-8964-2d8ed0dccf27",
   "metadata": {},
   "source": [
    "...and then adding up the squared residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b16662c-f6c4-47cf-9b8a-84fa63829e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssr_fit = np.sum(fit_residuals_squared)\n",
    "ssr_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628473d6-d767-46b5-a12c-94e869b96a65",
   "metadata": {},
   "source": [
    "Now that we have calculated SSR(mean) and SSR(fit), we can calculate\n",
    "<span style=\"font-size: 18px;\">\n",
    "$R^2 = \\frac{\\textrm{SSR(mean)} - \\textrm{SSR(fit)}}{\\textrm{SSR(mean)}}$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2376ecf-84bc-4556-abe5-32e9c0007a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r squared calculation\n",
    "r_squared = (ssr_mean - ssr_fit) / ssr_mean\n",
    "\n",
    "## print out r_squared\n",
    "r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd06a71d-d7f7-4262-82a7-4e36e923a082",
   "metadata": {},
   "source": [
    "BAM!\n",
    "\n",
    "Now let's compare that to the value stored in `results.rsquared`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7dda4b-d0c5-41b1-94b7-5be5f23a7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r squared from summary\n",
    "results.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c8ad4-5173-49f5-b38f-529acb06498e",
   "metadata": {},
   "source": [
    "...and we see that we got the same value, so we must have done all the math right.\n",
    "\n",
    "# BAM!\n",
    "\n",
    "Now let's learn how we can calculate a *p*-value for $R^2$ by with a histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803f948c-07ce-4f19-91ba-ad1ee407ad20",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57db0ea8-0803-47fa-b5fb-d2c0340a4198",
   "metadata": {},
   "source": [
    "# Calculating a *p*-value for the $R^2$ with a histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15ee82-cdfb-4938-a243-8d17967fdd87",
   "metadata": {},
   "source": [
    "Now that we know how to fit a linear regression line to data with `ols()` and calculate the $R^2$ value with `summary()` (and also by hand), let's learn how we can calculate a *p*-value using a histogram. This requires us to repeat the following steps a lot of times:\n",
    "\n",
    "- Generate random data\n",
    "- Fit a line to the data with `ols()`\n",
    "- Calculate the $R^2$ value for that fit with `summary()`\n",
    "- Store the $R^2$ value in an array\n",
    "\n",
    "Once we have an array of $R^2$ values calculated from random datasets, we pass it to `histplot()` to see how they are distributed and then calculate a *p*-value by seeing how many of the \"random\" $R^2$ values are greater than the one for our original dataset. We'll start by generating the \"random\" $R^2$ values with the following code (**NOTE:** It might take a minute or so for this code to run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5caea-db44-4583-8914-9ef5f6baa3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we're going to generate random datasets,\n",
    "# let's start by setting the seed so that the results\n",
    "# are reproducible\n",
    "np.random.seed(2)\n",
    "\n",
    "# To generate random datasets, we'll use two\n",
    "# normal distributions, one for the number of stores\n",
    "# and one for the revenue. These distributions\n",
    "# will be based on our observed data, so we\n",
    "# need to calculate their estimated\n",
    "# means and standard deviations.\n",
    "mean_num_stores = data['num_stores'].mean()\n",
    "sd_num_stores = data['num_stores'].std()\n",
    "\n",
    "mean_revenue = data['revenue'].mean()\n",
    "sd_revenue = data['revenue'].std()\n",
    "\n",
    "# Next, we define the number of random\n",
    "# datasets we want to create...\n",
    "num_rand_datasets = 10_000\n",
    "\n",
    "# ...and we define the number of data points\n",
    "# per dataset\n",
    "num_datapoints = len(data)\n",
    "\n",
    "# Create an empty array that is num_rand_datasets long\n",
    "rand_r_squared = np.empty(num_rand_datasets)\n",
    "\n",
    "# Here is the loop where we create a bunch of random datasets,\n",
    "# each with num_datapoints values, fit a linear regression\n",
    "# line to the random data, then calculate and store\n",
    "# the R-squared values\n",
    "for i in range(num_rand_datasets):\n",
    "    \n",
    "    ## generate random values for the number of stores\n",
    "    rand_num_stores = np.random.normal(loc=mean_num_stores,\n",
    "                                       scale=sd_num_stores,\n",
    "                                       size=num_datapoints)\n",
    "\n",
    "    ## generate random values for the revenue\n",
    "    rand_revenue = np.random.normal(loc=mean_revenue,\n",
    "                                    scale=sd_revenue,\n",
    "                                    size=num_datapoints)\n",
    "\n",
    "    ## bundle the random values together in a DataFrame\n",
    "    rand_data = pd.DataFrame({\n",
    "        'rand_num_stores': rand_num_stores,\n",
    "        'rand_revenue': rand_revenue})\n",
    "    \n",
    "    ## fit a linear regression line to the random data\n",
    "    rand_model = smf.ols(\"rand_revenue ~ rand_num_stores\", data=rand_data)\n",
    "    rand_results = rand_model.fit()\n",
    "    \n",
    "    ## save the R-squared value.\n",
    "    rand_r_squared[i] = rand_results.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a2b92-c4cf-40e1-a2b2-f530031ba873",
   "metadata": {},
   "source": [
    "Now let's draw a histogram of the $R^2$ values with the `histplot()` function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31939dd-3c15-42c4-8299-6b83734f3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=rand_r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146aee2-fbdf-460f-8bec-2bff838b0ae6",
   "metadata": {},
   "source": [
    "...and calculate the *p*-value as the precentage of \"random\" $R^2$ values greater than or equal to the one we got for our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd47d1b-33fa-4b36-a790-853e5e5e5ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of randomly generated rsquared >= the original rsquared\n",
    "num_greater = np.sum(rand_r_squared >= results.rsquared)\n",
    "\n",
    "# calculate the p-value \n",
    "p_value = num_greater / num_rand_datasets\n",
    "\n",
    "# print out the p-value\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc36ef5e-ed38-4ea4-9daf-34cddcec78c5",
   "metadata": {},
   "source": [
    "Thus, the *p*-value calculated with the histogram is 0.5318. Now let's compare that to the *p*-value stored in `results`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0076d2f8-42e6-45c6-8683-d191ae177732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the p-value for the slope coefficient (2nd coefficient)\n",
    "results.pvalues.num_stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17764e-dd57-43d4-a22c-a2386ce966a5",
   "metadata": {},
   "source": [
    "So, at last, we see that the two *p*-values are essentially the same.\n",
    "\n",
    "# BAM!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7635c41-2b14-4dfe-9756-247565112e8b",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62d897c-5fd3-4a28-b5e2-d2836a17aaca",
   "metadata": {},
   "source": [
    "# BONUS: Calculating an *F*-value and *p*-value using the Sum of the Squared Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9fff1f-557b-41ba-9440-49873bdbb826",
   "metadata": {},
   "source": [
    "The equation for *F* is..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8437367-d407-43a1-8f57-056eb55489e9",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 24px;\">\n",
    "$F = \\frac{[\\textrm{SSR(mean)} - \\textrm{SSR(fit)}] / (p_\\textrm{fit} - p_\\textrm{mean})}\n",
    "    {\\textrm{SSR(fit)} / (n - p_\\textrm{fit})}$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406f9882-82d2-43a2-a79a-ea1f6f962a2d",
   "metadata": {},
   "source": [
    "...so, all we have to do do calculate *F* is plug in the SSR(mean), the SSR(fit), $p_{\\textrm{fit}}$, the number of parameters required for the fitted line, which is **2** (one for the slope and one for the y-axis intercept), $p_{\\textrm{mean}}$, the number of parameters required for the mean, which is **1** (the y-axis intercept) and *n*, the number of datapoints, which is **3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078e2fd-2fe7-4f3b-9545-19f25b3255c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_numerator = (ssr_mean - ssr_fit) / (2 - 1)\n",
    "F_denominator = ssr_fit / (3 - 2)\n",
    "\n",
    "F = F_numerator / F_denominator\n",
    "F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6d7ec-9ab5-4d20-982d-9a980befc4ea",
   "metadata": {},
   "source": [
    "Now let's see if that matches the value in `results.fvalue`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fafa046-3949-47e5-b816-f60faaf00ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.fvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ca52e-5acb-42b4-b06c-b9bd24cd2b6c",
   "metadata": {},
   "source": [
    "...and it does! Now let's conver that *F*-value into a *p*-value. We do this with the `f.cdf()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca5dcf-1458-443d-a396-077a5e081d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, import 'f'\n",
    "from scipy.stats import f\n",
    "\n",
    "## now calculate the p-value (see notes below)\n",
    "p_value_f = 1-f.cdf(x=F, dfn=(2 - 1), dfd=(3 - 2))\n",
    "## NOTE: dfn = degrees of freedom in the numerator, which is DF1\n",
    "##       dfd = degrees of freedom in the denominator, which is DF2\n",
    "##\n",
    "## ALSO NOTE: To do calculate the probability of observing something to the *right* \n",
    "## of a specified x-axis coordinate, we have to remember that the total area under \n",
    "## the curve is 1 and `f.cdf()` only calculates cumulative probablities to the \n",
    "## *left* of a specified x-axis coordinate. Thus, we calculate the area of \n",
    "## something happening to the right of the x-axis coordinate by subtracting \n",
    "## the area to the left from 1.\n",
    "\n",
    "p_value_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43192ae4-ae7f-4734-b55a-da660a872f21",
   "metadata": {},
   "source": [
    "Now let's check to see if the *p*-value we calculated by hand matches the value stored in `results.pvalues.num_stores`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13680af-5658-4e4e-92b9-3589a87fcf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the p-value for the slope coefficient (2nd coefficient)\n",
    "results.pvalues.num_stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d270c4e4-b7ba-4358-8a6e-c69655246e7e",
   "metadata": {},
   "source": [
    "...and it does! Both are equatl to **0.5327**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84962981-fdc4-4799-904f-6eb172702bd5",
   "metadata": {},
   "source": [
    "# BONUS BAM!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a329f-f72a-4182-b283-560b9dfff1e1",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
